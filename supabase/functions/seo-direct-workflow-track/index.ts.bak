// Simplified SEO Direct Workflow with direct tracking
import { serve } from 'https://deno.land/std@0.177.0/http/server.ts';
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2.7.1';

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

// Easy model selection flag - change this to switch between models
// Options: "claude" (default) or "deepseek" (DeepSeek Reasoner)
const SEO_MODEL = "deepseek";

serve(async (req) => {
  // Handle CORS preflight requests
  if (req.method === 'OPTIONS') {
    return new Response('ok', { headers: corsHeaders });
  }

  let trackingId = null;
  let jobId = null;
  
  try {
    // Get Supabase URL and service role key from environment
    const SUPABASE_URL = Deno.env.get('SUPABASE_URL') || '';
    const SUPABASE_KEY = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') || '';
    
    if (!SUPABASE_URL || !SUPABASE_KEY) {
      throw new Error('Missing SUPABASE_URL or SUPABASE_SERVICE_ROLE_KEY');
    }
    
    // Parse request body for parameters
    let params = {};
    try {
      params = await req.json();
    } catch (e) {
      params = {};
    }
    
    const { pageId, url, openaiApiKey, model } = params;
    jobId = params.jobId;
    
    // Model override - allow request to specify which model to use
    const seoModel = model || SEO_MODEL;
    console.log(`SEO Model selection: ${seoModel}`);
    
    // We need either pageId, jobId, or url
    if (!pageId && !jobId && !url) {
      return new Response(
        JSON.stringify({
          success: false,
          error: 'Either pageId, jobId, or url is required'
        }),
        {
          headers: { ...corsHeaders, 'Content-Type': 'application/json' },
          status: 400
        }
      );
    }
    
    const supabase = createClient(SUPABASE_URL, SUPABASE_KEY);
    
    // Step 1: Insert tracking record directly if we have a job ID
    if (jobId) {
      console.log(`Creating tracking record for job ${jobId}`);
      
      // Get batch_id for the job
      const { data: job, error: jobError } = await supabase
        .from('crawl_jobs')
        .select('batch_id')
        .eq('id', jobId)
        .single();
        
      if (jobError) {
        console.error(`Error fetching job data: ${jobError.message}`);
      } else {
        // Delete any previous failed attempts
        await supabase
          .from('seo_processing_tracking')
          .delete()
          .eq('job_id', jobId)
          .in('success', [false, null]);
        
        // Create new tracking record
        const { data: tracking, error: trackingError } = await supabase
          .from('seo_processing_tracking')
          .insert({
            job_id: jobId,
            batch_id: job.batch_id,
            processing_start: new Date().toISOString(),
          })
          .select('id')
          .single();
          
        if (trackingError) {
          console.error(`Error creating tracking record: ${trackingError.message}`);
        } else {
          trackingId = tracking.id;
          console.log(`Created tracking record ${trackingId}`);
        }
      }
    }
    
    // Step 2: Get or create the page
    let page;
    
    if (pageId) {
      // Get existing page by ID
      const { data, error } = await supabase
        .from('pages')
        .select('*')
        .eq('id', pageId)
        .single();
        
      if (error) throw new Error(`Error getting page: ${error.message}`);
      if (!data) throw new Error(`Page with ID ${pageId} not found`);
      
      page = data;
    } else if (jobId) {
      // Get page from crawl job
      const { data: job, error: jobError } = await supabase
        .from('crawl_jobs')
        .select('page_id, url, html, html_length')
        .eq('id', jobId)
        .single();
        
      if (jobError) throw new Error(`Error getting job: ${jobError.message}`);
      if (!job) throw new Error(`Job with ID ${jobId} not found`);
      if (!job.page_id) throw new Error(`Job ${jobId} has no associated page_id`);
      
      // Get the page
      const { data: pageData, error: pageError } = await supabase
        .from('pages')
        .select('*')
        .eq('id', job.page_id)
        .single();
        
      if (pageError) throw new Error(`Error getting page: ${pageError.message}`);
      if (!pageData) throw new Error(`Page with ID ${job.page_id} not found`);
      
      page = pageData;
      
      // Update page with HTML if needed
      if (job.html && (!page.html || page.html_length === 0)) {
        const { error: updateError } = await supabase
          .from('pages')
          .update({
            html: job.html,
            html_length: job.html_length,
            last_crawled: new Date().toISOString()
          })
          .eq('id', job.page_id);
          
        if (updateError) {
          console.error(`Error updating page with HTML: ${updateError.message}`);
        }
      }
    } else if (url) {
      // Check if page exists
      const { data: existingPage, error: existingError } = await supabase
        .from('pages')
        .select('*')
        .eq('url', url)
        .single();
        
      if (!existingError && existingPage) {
        page = existingPage;
      } else {
        // Create new page
        const { data: newPage, error: createError } = await supabase
          .from('pages')
          .insert({ url })
          .select()
          .single();
          
        if (createError) throw new Error(`Error creating page: ${createError.message}`);
        
        page = newPage;
      }
    }
    
    console.log(`Working with page ID: ${page.id}, URL: ${page.url}`);
    
    // Variables to store results
    let gscSuccessful = false;
    let seoAnalysisId = null;
    let seoSuccess = false;
    let errorMessage = null;
    
    // Step 3: First ensure we have keywords by either getting GSC data or extracting from content
    console.log(`Ensuring keywords are available for ${page.url}`);

    // Helper function to extract keywords from content
    async function extractKeywords() {
      console.log(`Extracting keywords from content for ${page.url}`);
      
      try {
        const keywordResponse = await fetch(`${SUPABASE_URL}/functions/v1/extract-content-keywords`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${SUPABASE_KEY}`
          },
          body: JSON.stringify({
            pageId: page.id,
            saveToDatabase: true
          })
        });
        
        let responseText = '';
        try {
          responseText = await keywordResponse.text();
          console.log(`Keyword extraction response status: ${keywordResponse.status}`);
          console.log(`Keyword extraction response preview: ${responseText.substring(0, 200)}...`);
        } catch (textError) {
          console.error(`Error getting response text: ${textError.message}`);
        }
        
        if (keywordResponse.ok) {
          try {
            const keywordResult = JSON.parse(responseText);
            if (keywordResult.success) {
              console.log(`Successfully extracted ${keywordResult.gscCompatibleKeywords?.length || 0} keywords from content`);
              return true;
            } else {
              console.error(`Keyword extraction reported failure: ${keywordResult.error || 'Unknown error'}`);
            }
          } catch (parseError) {
            console.error(`Error parsing keyword extraction response: ${parseError.message}`);
          }
        } else {
          console.error(`Error extracting keywords: ${keywordResponse.status}`);
        }
      } catch (keywordError) {
        console.error(`Error calling extract-content-keywords: ${keywordError.message}`);
      }
      
      return false;
    }
    
    // Helper function to check if keywords exist in the recommendations
    async function checkForExistingKeywords() {
      try {
        // Check if there's already keywords in the page_seo_recommendations table
        const { data: recData, error: recError } = await supabase
          .from('page_seo_recommendations')
          .select('keywords')
          .eq('page_id', page.id)
          .single();
          
        if (!recError && recData?.keywords && Array.isArray(recData.keywords) && recData.keywords.length > 0) {
          console.log(`Found ${recData.keywords.length} existing keywords in page_seo_recommendations for page ${page.id}`);
          return true;
        }
      } catch (error) {
        console.error(`Error checking for existing keywords in recommendations: ${error.message}`);
      }
      
      return false;
    }
    
    // Helper function to check if GSC keywords already exist in the database
    async function checkForExistingGSCKeywords() {
      try {
        // Check if there are already GSC keywords stored
        const { data: gscData, error: gscError } = await supabase
          .from('gsc_keywords')
          .select('count(*)', { count: 'exact' })
          .eq('page_id', page.id);
          
        const keywordCount = gscData?.count || 0;
        
        if (keywordCount > 0) {
          console.log(`Found ${keywordCount} existing GSC keywords for page ${page.id}`);
          
          // Copy these to the recommendations table
          const { data: gscKeywords, error: fetchError } = await supabase
            .from('gsc_keywords')
            .select('keyword, clicks, impressions, position, ctr')
            .eq('page_id', page.id)
            .order('impressions', { ascending: false })
            .limit(20);
            
          if (!fetchError && gscKeywords && gscKeywords.length > 0) {
            console.log(`Copying ${gscKeywords.length} existing GSC keywords to recommendations`);
            
            // Copy to page_seo_recommendations
            const { data: existingRec, error: checkError } = await supabase
              .from('page_seo_recommendations')
              .select('id')
              .eq('page_id', page.id)
              .limit(1);
              
            if (!checkError) {
              if (existingRec && existingRec.length > 0) {
                // Update existing record
                await supabase
                  .from('page_seo_recommendations')
                  .update({
                    keywords: gscKeywords,
                    has_gsc_data: true, // Mark as having GSC data
                    updated_at: new Date().toISOString()
                  })
                  .eq('id', existingRec[0].id);
              } else {
                // Insert new record
                await supabase
                  .from('page_seo_recommendations')
                  .insert({
                    page_id: page.id,
                    url: page.url,
                    keywords: gscKeywords,
                    has_gsc_data: true, // Mark as having GSC data
                    created_at: new Date().toISOString(),
                    updated_at: new Date().toISOString()
                  });
              }
              
              console.log('Successfully copied existing GSC keywords to recommendations');
              return true;
            }
          }
        }
      } catch (error) {
        console.error(`Error checking for existing GSC keywords: ${error.message}`);
      }
      
      return false;
    }
    
    // MAIN WORKFLOW CHANGE: Always try to get GSC data first
    let hasKeywords = false;
    // Reset gscSuccessful flag
    gscSuccessful = false;
    
    // Step 1: Always try fetching fresh GSC data first, regardless of existing keywords
    try {
      console.log(`Fetching fresh GSC data for ${page.url} as first step`);
      // Call GSC data function (api-first version will try API, then database, then fallbacks)
      const gscResponse = await fetch(`${SUPABASE_URL}/functions/v1/fetch-gsc-data`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${SUPABASE_KEY}`
        },
        body: JSON.stringify({
          pageId: page.id,
          url: page.url
        })
      });
      
      if (gscResponse.ok) {
        const gscResult = await gscResponse.json();
        if (gscResult.success) {
          gscSuccessful = true;
          
          // After GSC processing, check if we now have usable keywords
          hasKeywords = await checkForExistingGSCKeywords();
          
          console.log(`GSC data fetch result: success=${gscResult.success}, hasKeywords=${hasKeywords}, source=${gscResult.source || 'unknown'}`);
        }
      }
    } catch (gscError) {
      console.error(`Initial GSC data fetch error: ${gscError.message}`);
    }
    
    // Step 2: If we still don't have keywords, check existing recommendations
    if (!hasKeywords) {
      console.log(`No GSC keywords found, checking for existing keywords in recommendations`);
      hasKeywords = await checkForExistingKeywords();
    }
        
    // Step 3: If we still don't have keywords, try AI content extraction as a last resort 
    if (!hasKeywords) {
      console.log(`No usable GSC or existing keywords found, trying AI extraction for ${page.url}`);
      hasKeywords = await extractKeywords();
    }
    
    // Log keyword availability status
    if (hasKeywords) {
      console.log(`✅ Keywords are available for ${page.url}`);
      gscSuccessful = true;
    } else {
      console.log(`⚠️ Could not get keywords for ${page.url}`);
    }
    
    // Step 4: Run on-page SEO analysis
    console.log(`Running on-page SEO analysis for ${page.url}`);
    
    try {
      // Call on-page SEO analysis function
      const seoResponse = await fetch(`${SUPABASE_URL}/functions/v1/analyze-page-seo`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${SUPABASE_KEY}`
        },
        body: JSON.stringify({
          pageId: page.id,
          url: page.url,
          openaiApiKey
        })
      });
      
      if (!seoResponse.ok) {
        const errorText = await seoResponse.text();
        errorMessage = `SEO analysis failed: ${seoResponse.status} ${seoResponse.statusText} - ${errorText}`;
        console.error(errorMessage);
      } else {
        console.log(`Successfully analyzed SEO for ${page.url}`);
        const seoResult = await seoResponse.json();
        
        if (seoResult.success && seoResult.analysis && seoResult.analysis.id) {
          seoAnalysisId = seoResult.analysis.id;
          seoSuccess = true;
        }
      }
    } catch (error) {
      errorMessage = `SEO analysis exception: ${error.message}`;
      console.error(errorMessage);
    }
    
    // Step 5: Generate SEO elements (title, h1, h2, paragraph)
    console.log(`Generating SEO elements for ${page.url}`);
    
    try {
      // First try calling the generate-seo-elements function
      let success = false;
      
      try {
        // Determine which model/function to use based on the seoModel value
        const seoFunctionName = seoModel === "deepseek" ? "generate-seo-elements-ds" : "generate-seo-elements";
        console.log(`Using ${seoFunctionName} with ${seoModel} model for SEO element generation`);
        
        // Call the appropriate SEO elements generation function
        const elementsResponse = await fetch(`${SUPABASE_URL}/functions/v1/${seoFunctionName}`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${SUPABASE_KEY}`
          },
          body: JSON.stringify({
            pageId: page.id,
            url: page.url
          })
        });
        
        if (!elementsResponse.ok) {
          const errorText = await elementsResponse.text();
          console.error(`SEO elements generation failed: ${elementsResponse.status} ${elementsResponse.statusText} - ${errorText}`);
        } else {
          console.log(`Successfully generated SEO elements for ${page.url}`);
          const elementsResult = await elementsResponse.json();
          
          if (elementsResult.success && elementsResult.seoElements) {
            console.log(`Generated SEO elements: Title, H1, H2, and paragraph`);
            success = true;
          }
        }
      } catch (apiError) {
        console.error(`API call exception: ${apiError.message}`);
      }
      
      // If the API call failed, insert placeholder elements directly
      if (!success) {
        console.log(`Using direct insertion fallback for SEO elements for ${page.url}`);
        
        // Extract domain and path for better title/description
        const urlObj = new URL(page.url);
        const domain = urlObj.hostname.replace('www.', '');
        const path = urlObj.pathname.split('/').filter(p => p).join(' ');
        
        // Create placeholder SEO elements - using delete then insert approach instead of upsert
        
        // First check if record exists
        const { data: existingRec, error: checkError } = await supabase
          .from('page_seo_recommendations')
          .select('id')
          .eq('page_id', page.id)
          .limit(1);
          
        if (!checkError && existingRec && existingRec.length > 0) {
          // Update existing record
          const { data: updateResult, error: updateError } = await supabase
            .from('page_seo_recommendations')
            .update({
              url: page.url,
              title: `${path ? path.replace(/-/g, ' ') : 'Products'} | ${domain}`,
              meta_description: `Explore ${path ? path.replace(/-/g, ' ') : 'our products'} at ${domain}. Find great deals on ${urlObj.pathname.split('/').pop()?.replace(/-/g, ' ') || 'items'}.`,
              h1: `${path ? path.split(' ').map(w => w.charAt(0).toUpperCase() + w.slice(1)).join(' ') : 'Products'}`,
              h2: `Explore Our ${urlObj.pathname.split('/').pop()?.replace(/-/g, ' ').split(' ').map(w => w.charAt(0).toUpperCase() + w.slice(1)).join(' ') || 'Collection'}`,
              h4: `Top ${urlObj.pathname.split('/').pop()?.replace(/-/g, ' ').split(' ').map(w => w.charAt(0).toUpperCase() + w.slice(1)).join(' ') || 'Options'}`, // Added h4
              paragraph: `Browse our selection of ${path ? path.replace(/-/g, ' ') : 'products'} designed to meet your needs. We offer quality items at competitive prices, with options for every preference and budget.`,
              updated_at: new Date().toISOString()
            })
            .eq('id', existingRec[0].id)
            .select();
            
          if (updateError) {
            console.error(`Error updating SEO elements: ${updateError.message}`);
          } else {
            console.log(`Successfully updated SEO elements for ${page.url}`);
          }
          
          var insertResult = updateResult;
          var insertError = updateError;
        } else {
          // Insert new record
          const { data: newResult, error: insertError } = await supabase
            .from('page_seo_recommendations')
            .insert({
              page_id: page.id,
              url: page.url,
              title: `${path ? path.replace(/-/g, ' ') : 'Products'} | ${domain}`,
              meta_description: `Explore ${path ? path.replace(/-/g, ' ') : 'our products'} at ${domain}. Find great deals on ${urlObj.pathname.split('/').pop()?.replace(/-/g, ' ') || 'items'}.`,
              h1: `${path ? path.split(' ').map(w => w.charAt(0).toUpperCase() + w.slice(1)).join(' ') : 'Products'}`,
              h2: `Explore Our ${urlObj.pathname.split('/').pop()?.replace(/-/g, ' ').split(' ').map(w => w.charAt(0).toUpperCase() + w.slice(1)).join(' ') || 'Collection'}`,
              h4: `Top ${urlObj.pathname.split('/').pop()?.replace(/-/g, ' ').split(' ').map(w => w.charAt(0).toUpperCase() + w.slice(1)).join(' ') || 'Options'}`, // Added h4
              paragraph: `Browse our selection of ${path ? path.replace(/-/g, ' ') : 'products'} designed to meet your needs. We offer quality items at competitive prices, with options for every preference and budget.`,
              created_at: new Date().toISOString(),
              updated_at: new Date().toISOString()
            })
            .select();
            
          if (insertError) {
            console.error(`Error inserting SEO elements: ${insertError.message}`);
          } else {
            console.log(`Successfully inserted SEO elements for ${page.url}`);
          }
          
          var insertResult = newResult;
        }
          
        if (insertError) {
          console.error(`Error in direct SEO elements insertion: ${insertError.message}`);
        } else {
          console.log(`Successfully inserted placeholder SEO elements for ${page.url}`);
        }
      }
    } catch (error) {
      console.error(`SEO elements generation exception: ${error.message}`);
    }
    
    // Step 5: Update tracking record if we have one
    if (trackingId) {
      console.log(`Updating tracking record ${trackingId} with success=${seoSuccess}`);
      
      const { error: updateError } = await supabase
        .from('seo_processing_tracking')
        .update({
          processing_end: new Date().toISOString(),
          success: seoSuccess,
          error_message: errorMessage,
          seo_recommendation_id: seoAnalysisId,
          updated_at: new Date().toISOString()
        })
        .eq('id', trackingId);
        
      if (updateError) {
        console.error(`Error updating tracking record: ${updateError.message}`);
      } else {
        console.log(`Successfully updated tracking record`);
      }
    }
    
    return new Response(
      JSON.stringify({
        success: true,
        message: `Successfully ran streamlined SEO workflow for ${page.url}`,
        page: {
          id: page.id,
          url: page.url
        },
        seo_analysis_id: seoAnalysisId,
        gsc_fetched: gscSuccessful,
        tracking_id: trackingId,
        model_used: seoModel
      }),
      {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' }
      }
    );
  } catch (error) {
    console.error(`Error: ${error.message}`);
    
    // Update tracking record with error
    if (trackingId) {
      const supabase = createClient(
        Deno.env.get('SUPABASE_URL') || '',
        Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') || ''
      );
      
      await supabase
        .from('seo_processing_tracking')
        .update({
          processing_end: new Date().toISOString(),
          success: false,
          error_message: error.message,
          updated_at: new Date().toISOString()
        })
        .eq('id', trackingId);
    }
    
    return new Response(
      JSON.stringify({
        success: false,
        error: error.message,
        jobId: jobId,
        trackingId: trackingId
      }),
      {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        status: 500
      }
    );
  }
});